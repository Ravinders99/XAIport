{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the target label number:  208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 21:59:18,750 - INFO - Loaded 19796 video labels\n",
      "2025-02-12 21:59:18,750 - INFO - Unique labels in the dataset: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399}\n",
      "2025-02-12 21:59:18,751 - INFO - Found 50 videos for label 208\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/DYpTE_n-Wvk.mp4                       | 0/50 [00:00<?, ?it/s]\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/A1GyD1xuAbk.mp4\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/9E1KtFdU2g0.mp4\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/I5VWtiujA5s.mp4\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/bkObwMM5ZFY.mp4\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/yrADpETYnUg.mp4\n",
      "2025-02-12 21:59:18,752 - WARNING - Video file not found: dataprocess/test_video/K8vBVVe_QSs.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/fWKNCJr_RxA.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/IK8q5utAAF0.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/-HxBTALkZT4.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/q_AVvGVuIzo.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/2gD3nshZPBw.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/HL02WfHzH1s.mp4\n",
      "2025-02-12 21:59:18,753 - WARNING - Video file not found: dataprocess/test_video/_rS3ufHdRtQ.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/zrXk32DM3Fw.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/gSMM1fjD_xE.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/K-FMTC9VWG8.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/Wg6hdKMUf9M.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/twzMs05FvWQ.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/JmjV8r8tvz0.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/ixMPVi3Zr9s.mp4\n",
      "2025-02-12 21:59:18,754 - WARNING - Video file not found: dataprocess/test_video/8NbCX98lCIU.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/-b6gqj_mZOs.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/f5WUgvASdkM.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/chN87Lwj4RM.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/CXeq7GiuePY.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/p8On73vMA1A.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/TOutc69ZBSY.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/9Rt2EMsYXXQ.mp4\n",
      "2025-02-12 21:59:18,755 - WARNING - Video file not found: dataprocess/test_video/-vRY0Qrvz9A.mp4\n",
      "2025-02-12 21:59:18,756 - WARNING - Video file not found: dataprocess/test_video/hORZWmhCk3c.mp4\n",
      "\n",
      "\u001b[Acessing frames:   0%|                                                                                              | 0/300 [00:00<?, ?it/s]\n",
      "\u001b[Acessing frames:   3%|██▎                                                                                   | 8/300 [00:03<02:09,  2.25it/s]\n",
      "\u001b[Acessing frames:   5%|████▎                                                                                | 15/300 [00:06<02:12,  2.15it/s]\n",
      "\u001b[Acessing frames:   7%|██████▏                                                                              | 22/300 [00:10<02:12,  2.10it/s]\n",
      "\u001b[Acessing frames:  10%|████████▏                                                                            | 29/300 [00:13<02:10,  2.08it/s]\n",
      "\u001b[Acessing frames:  12%|██████████▏                                                                          | 36/300 [00:17<02:06,  2.09it/s]\n",
      "\u001b[Acessing frames:  14%|████████████▏                                                                        | 43/300 [00:20<02:03,  2.09it/s]\n",
      "\u001b[Acessing frames:  17%|██████████████▏                                                                      | 50/300 [00:23<01:59,  2.10it/s]\n",
      "\u001b[Acessing frames:  19%|████████████████▏                                                                    | 57/300 [00:27<01:55,  2.10it/s]\n",
      "\u001b[Acessing frames:  21%|██████████████████▏                                                                  | 64/300 [00:30<01:52,  2.10it/s]\n",
      "\u001b[Acessing frames:  24%|████████████████████                                                                 | 71/300 [00:33<01:49,  2.10it/s]\n",
      "\u001b[Acessing frames:  26%|██████████████████████                                                               | 78/300 [00:37<01:45,  2.09it/s]\n",
      "\u001b[Acessing frames:  28%|████████████████████████                                                             | 85/300 [00:40<01:43,  2.09it/s]\n",
      "\u001b[Acessing frames:  31%|██████████████████████████                                                           | 92/300 [00:44<01:41,  2.06it/s]\n",
      "\u001b[Acessing frames:  33%|████████████████████████████                                                         | 99/300 [00:47<01:37,  2.06it/s]\n",
      "\u001b[Acessing frames:  35%|█████████████████████████████▋                                                      | 106/300 [00:50<01:33,  2.06it/s]\n",
      "\u001b[Acessing frames:  38%|███████████████████████████████▋                                                    | 113/300 [00:54<01:30,  2.07it/s]\n",
      "\u001b[Acessing frames:  40%|█████████████████████████████████▌                                                  | 120/300 [00:57<01:26,  2.07it/s]\n",
      "\u001b[Acessing frames:  42%|███████████████████████████████████▌                                                | 127/300 [01:00<01:23,  2.08it/s]\n",
      "\u001b[Acessing frames:  45%|█████████████████████████████████████▌                                              | 134/300 [01:04<01:19,  2.09it/s]\n",
      "\u001b[Acessing frames:  47%|███████████████████████████████████████▍                                            | 141/300 [01:07<01:15,  2.09it/s]\n",
      "\u001b[Acessing frames:  49%|█████████████████████████████████████████▍                                          | 148/300 [01:10<01:12,  2.09it/s]\n",
      "\u001b[Acessing frames:  52%|███████████████████████████████████████████▍                                        | 155/300 [01:14<01:09,  2.10it/s]\n",
      "\u001b[Acessing frames:  54%|█████████████████████████████████████████████▎                                      | 162/300 [01:17<01:06,  2.07it/s]\n",
      "\u001b[Acessing frames:  56%|███████████████████████████████████████████████▎                                    | 169/300 [01:20<01:02,  2.09it/s]\n",
      "\u001b[Acessing frames:  59%|█████████████████████████████████████████████████▎                                  | 176/300 [01:24<00:59,  2.09it/s]\n",
      "\u001b[Acessing frames:  61%|███████████████████████████████████████████████████▏                                | 183/300 [01:27<00:56,  2.09it/s]\n",
      "\u001b[Acessing frames:  63%|█████████████████████████████████████████████████████▏                              | 190/300 [01:30<00:52,  2.09it/s]\n",
      "\u001b[Acessing frames:  66%|███████████████████████████████████████████████████████▏                            | 197/300 [01:34<00:48,  2.10it/s]\n",
      "\u001b[Acessing frames:  68%|█████████████████████████████████████████████████████████                           | 204/300 [01:37<00:45,  2.11it/s]\n",
      "\u001b[Acessing frames:  70%|███████████████████████████████████████████████████████████                         | 211/300 [01:40<00:42,  2.10it/s]\n",
      "\u001b[Acessing frames:  73%|█████████████████████████████████████████████████████████████                       | 218/300 [01:44<00:38,  2.10it/s]\n",
      "\u001b[Acessing frames:  75%|███████████████████████████████████████████████████████████████                     | 225/300 [01:47<00:35,  2.09it/s]\n",
      "\u001b[Acessing frames:  77%|████████████████████████████████████████████████████████████████▉                   | 232/300 [01:51<00:32,  2.08it/s]\n",
      "\u001b[Acessing frames:  80%|██████████████████████████████████████████████████████████████████▉                 | 239/300 [01:54<00:29,  2.09it/s]\n",
      "\u001b[Acessing frames:  82%|████████████████████████████████████████████████████████████████████▉               | 246/300 [01:57<00:25,  2.10it/s]\n",
      "\u001b[Acessing frames:  84%|██████████████████████████████████████████████████████████████████████▊             | 253/300 [02:00<00:22,  2.11it/s]\n",
      "\u001b[Acessing frames:  87%|████████████████████████████████████████████████████████████████████████▊           | 260/300 [02:04<00:18,  2.11it/s]\n",
      "\u001b[Acessing frames:  89%|██████████████████████████████████████████████████████████████████████████▊         | 267/300 [02:07<00:15,  2.12it/s]\n",
      "\u001b[Acessing frames:  91%|████████████████████████████████████████████████████████████████████████████▋       | 274/300 [02:10<00:12,  2.13it/s]\n",
      "\u001b[Acessing frames:  94%|██████████████████████████████████████████████████████████████████████████████▋     | 281/300 [02:14<00:08,  2.13it/s]\n",
      "\u001b[Acessing frames:  96%|████████████████████████████████████████████████████████████████████████████████▋   | 288/300 [02:17<00:05,  2.12it/s]\n",
      "Processing frames: 100%|████████████████████████████████████████████████████████████████████████████████████| 300/300 [02:20<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_4_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_36_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_116_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_174_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_228_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_244_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_326_spatial_attention.png\n",
      "Frame not found: video_results/__lt03EF4ao/frames/__lt03EF4ao_frame_340_spatial_attention.png\n",
      "No frames were loaded for __lt03EF4ao. Check the 'frames' directory and file names.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 22:01:43,424 - WARNING - Video file not found: dataprocess/test_video/q7tvMXsXCXQ.mp4              | 32/50 [02:24<01:21,  4.52s/it]\n",
      "2025-02-12 22:01:43,424 - WARNING - Video file not found: dataprocess/test_video/odt54ATghjQ.mp4\n",
      "2025-02-12 22:01:43,424 - WARNING - Video file not found: dataprocess/test_video/yUb9zN3Nkbg.mp4\n",
      "2025-02-12 22:01:43,424 - WARNING - Video file not found: dataprocess/test_video/uzsJgLcvHoQ.mp4\n",
      "2025-02-12 22:01:43,425 - WARNING - Video file not found: dataprocess/test_video/NVAuLnPUsgo.mp4\n",
      "2025-02-12 22:01:43,425 - WARNING - Video file not found: dataprocess/test_video/rtCrCuN46WM.mp4\n",
      "2025-02-12 22:01:43,425 - WARNING - Video file not found: dataprocess/test_video/ZcYT82-Agrc.mp4\n",
      "2025-02-12 22:01:43,425 - WARNING - Video file not found: dataprocess/test_video/WV1LT7Z2pcs.mp4\n",
      "2025-02-12 22:01:43,425 - WARNING - Video file not found: dataprocess/test_video/KlzJI2wQafk.mp4\n",
      "2025-02-12 22:01:43,425 - WARNING - Video file not found: dataprocess/test_video/7cGg4sdG5KQ.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/xME1X5_D88c.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/yrfFFQJNn1Q.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/1pWCgNggH5M.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/Nunqc8rPktk.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/MXt2pomyyt8.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/1Mc6Krmttw0.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/L89FX34lmsI.mp4\n",
      "2025-02-12 22:01:43,426 - WARNING - Video file not found: dataprocess/test_video/NcuHH57heWE.mp4\n",
      "Processing videos: 100%|██████████████████████████████████████████████████████████████████████████████████████| 50/50 [02:24<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample frames visualization saved to: video_results/__lt03EF4ao/__lt03EF4ao_sample_frames.png\n",
      "Processed __lt03EF4ao\n",
      "Predicted Label: 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import av\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import TimesformerForVideoClassification, AutoImageProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import json\n",
    "import logging\n",
    "from scipy.signal import savgol_filter, find_peaks\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class AttentionExtractor:\n",
    "    def __init__(self, model_name, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = TimesformerForVideoClassification.from_pretrained(model_name)\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "    def extract_attention(self, frames):\n",
    "        inputs = self.image_processor(frames, return_tensors=\"pt\").to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs, output_attentions=True)\n",
    "        last_layer_attention = outputs.attentions[-1]\n",
    "        spatial_attention = last_layer_attention.mean(1)\n",
    "        return spatial_attention.cpu().numpy(), outputs.logits.cpu().numpy()\n",
    "\n",
    "    def apply_attention_heatmap(self, frame, attention):\n",
    "        att_map = attention[1:].reshape(int(np.sqrt(attention.shape[0]-1)), -1)\n",
    "        att_resized = cv2.resize(att_map, (frame.shape[1], frame.shape[0]))\n",
    "        att_norm = (att_resized - att_resized.min()) / (att_resized.max() - att_resized.min())\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * att_norm), cv2.COLORMAP_JET)\n",
    "        blend = cv2.addWeighted(frame, 0.7, heatmap, 0.3, 0)\n",
    "        return blend\n",
    "\n",
    "def multi_scale_attention(extractor, frames):\n",
    "    scales = [0.5, 0.75, 1.0, 1.25, 1.5]\n",
    "    attentions = []\n",
    "    for scale in scales:\n",
    "        scaled_frames = [cv2.resize(frame, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR) for frame in frames]\n",
    "        attention, _ = extractor.extract_attention(scaled_frames)\n",
    "        attentions.append(attention)\n",
    "    return np.mean(attentions, axis=0)\n",
    "\n",
    "def exponential_smoothing(data, alpha=0.3):\n",
    "    smoothed = [data[0]]\n",
    "    for i in range(1, len(data)):\n",
    "        smoothed.append(alpha * data[i] + (1 - alpha) * smoothed[-1])\n",
    "    return smoothed\n",
    "\n",
    "def process_video(video_path, output_dir, extractor, sampling_rate=2, temporal_smoothing_window=5):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    frames_dir = os.path.join(output_dir, 'frames')\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    container = av.open(video_path)\n",
    "    video_stream = container.streams.video[0]\n",
    "    fps = video_stream.average_rate\n",
    "    total_frames = video_stream.frames\n",
    "    \n",
    "    # 创建输出视频文件\n",
    "    output_path = os.path.join(output_dir, f\"{os.path.basename(video_path).split('.')[0]}_heatmap.mp4\")\n",
    "    output = av.open(output_path, mode='w')\n",
    "    output_stream = output.add_stream('h264', rate=fps)\n",
    "    output_stream.width = video_stream.width\n",
    "    output_stream.height = video_stream.height\n",
    "    output_stream.pix_fmt = 'yuv420p'\n",
    "\n",
    "    frames = []\n",
    "    attention_data = []\n",
    "    frame_count = 0\n",
    "    attention_buffer = []\n",
    "    all_logits = []\n",
    "\n",
    "    for frame in tqdm(container.decode(video=0), desc=\"Processing frames\", total=total_frames):\n",
    "        frame_rgb = frame.to_rgb().to_ndarray()\n",
    "        frames.append(frame_rgb)\n",
    "        \n",
    "        if len(frames) == 8:\n",
    "            spatial_attention = multi_scale_attention(extractor, frames)\n",
    "            logits = extractor.extract_attention(frames)[1]\n",
    "            all_logits.append(logits)\n",
    "            \n",
    "            for i in range(8):\n",
    "                attention = spatial_attention[0, i+1]\n",
    "                attention_buffer.append(attention)\n",
    "                \n",
    "                if len(attention_buffer) >= temporal_smoothing_window:\n",
    "                    smoothed_attention = np.mean(attention_buffer[-temporal_smoothing_window:], axis=0)\n",
    "                    heatmap_frame = extractor.apply_attention_heatmap(frames[i], smoothed_attention)\n",
    "                    \n",
    "                    if frame_count % sampling_rate == 0:\n",
    "                        frame_filename = f\"{os.path.basename(video_path).split('.')[0]}_frame_{frame_count+1}_spatial_attention.png\"\n",
    "                        cv2.imwrite(os.path.join(frames_dir, frame_filename), cv2.cvtColor(heatmap_frame, cv2.COLOR_RGB2BGR))\n",
    "                        \n",
    "                        attention_data.append({\n",
    "                            \"frame_index\": frame_count,\n",
    "                            \"max_attention\": float(smoothed_attention[1:].max()),\n",
    "                            \"min_attention\": float(smoothed_attention[1:].min()),\n",
    "                            \"mean_attention\": float(smoothed_attention[1:].mean())\n",
    "                        })\n",
    "                    \n",
    "                    # 将每一帧都写入输出视频\n",
    "                    out_frame = av.VideoFrame.from_ndarray(heatmap_frame, format='rgb24')\n",
    "                    packet = output_stream.encode(out_frame)\n",
    "                    output.mux(packet)\n",
    "                \n",
    "                frame_count += 1\n",
    "            \n",
    "            frames = frames[7:]\n",
    "\n",
    "    # Process remaining frames\n",
    "    if frames:\n",
    "        padding = [frames[-1]] * (8 - len(frames))\n",
    "        spatial_attention = multi_scale_attention(extractor, frames + padding)\n",
    "        logits = extractor.extract_attention(frames + padding)[1]\n",
    "        all_logits.append(logits)\n",
    "        \n",
    "        for i in range(len(frames)):\n",
    "            attention = spatial_attention[0, i+1]\n",
    "            attention_buffer.append(attention)\n",
    "            \n",
    "            smoothed_attention = np.mean(attention_buffer[-temporal_smoothing_window:], axis=0)\n",
    "            heatmap_frame = extractor.apply_attention_heatmap(frames[i], smoothed_attention)\n",
    "            \n",
    "            if frame_count % sampling_rate == 0:\n",
    "                frame_filename = f\"{os.path.basename(video_path).split('.')[0]}_frame_{frame_count+1}_spatial_attention.png\"\n",
    "                cv2.imwrite(os.path.join(frames_dir, frame_filename), cv2.cvtColor(heatmap_frame, cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                attention_data.append({\n",
    "                    \"frame_index\": frame_count,\n",
    "                    \"max_attention\": float(smoothed_attention[1:].max()),\n",
    "                    \"min_attention\": float(smoothed_attention[1:].min()),\n",
    "                    \"mean_attention\": float(smoothed_attention[1:].mean())\n",
    "                })\n",
    "            \n",
    "            # 将每一帧都写入输出视频\n",
    "            out_frame = av.VideoFrame.from_ndarray(heatmap_frame, format='rgb24')\n",
    "            packet = output_stream.encode(out_frame)\n",
    "            output.mux(packet)\n",
    "            \n",
    "            frame_count += 1\n",
    "\n",
    "    # Flush encoder\n",
    "    packet = output_stream.encode(None)\n",
    "    output.mux(packet)\n",
    "    output.close()\n",
    "\n",
    "    # Apply exponential smoothing to attention data\n",
    "    smoothed_attention = exponential_smoothing([frame['mean_attention'] for frame in attention_data])\n",
    "    for i, att in enumerate(smoothed_attention):\n",
    "        attention_data[i]['mean_attention'] = att\n",
    "\n",
    "    # Save attention data\n",
    "    with open(os.path.join(output_dir, f\"{os.path.basename(video_path).split('.')[0]}_rs.json\"), 'w') as f:\n",
    "        json.dump(attention_data, f)\n",
    "\n",
    "    overall_logits = np.mean(all_logits, axis=0)\n",
    "    predicted_label = int(np.argmax(overall_logits))\n",
    "\n",
    "    return predicted_label, frames_dir, os.path.join(output_dir, f\"{os.path.basename(video_path).split('.')[0]}_rs.json\"), output_path\n",
    "\n",
    "def create_sample_frames_visualization(video_name, num_segments=8, results_dir='attention_results'):\n",
    "    try:\n",
    "        # Load data\n",
    "        json_path = os.path.join(results_dir, f\"{video_name}_rs.json\")\n",
    "        if not os.path.exists(json_path):\n",
    "            raise FileNotFoundError(f\"JSON file not found: {json_path}\")\n",
    "        \n",
    "        with open(json_path, 'r') as f:\n",
    "            attention_data = json.load(f)\n",
    "        \n",
    "        # Extract temporal attention\n",
    "        temporal_attention = np.array([frame['mean_attention'] for frame in attention_data])\n",
    "        frame_indices = np.array([frame['frame_index'] for frame in attention_data])\n",
    "        \n",
    "        # Apply Savitzky-Golay filter for additional smoothing\n",
    "        window_length = min(len(temporal_attention) // 2 * 2 + 1, 21)  # Must be odd and not exceed data length\n",
    "        temporal_attention_smoothed = savgol_filter(temporal_attention, window_length, 3)\n",
    "        \n",
    "        # Normalize temporal attention\n",
    "        temporal_attention_smoothed = (temporal_attention_smoothed - temporal_attention_smoothed.min()) / (temporal_attention_smoothed.max() - temporal_attention_smoothed.min())\n",
    "        \n",
    "        # Select key frames based on local maxima\n",
    "        peaks, _ = find_peaks(temporal_attention_smoothed, distance=len(temporal_attention_smoothed)//num_segments)\n",
    "        if len(peaks) < num_segments:\n",
    "            additional_frames = np.linspace(0, len(temporal_attention_smoothed)-1, num_segments-len(peaks), dtype=int)\n",
    "            key_frame_indices = np.sort(np.concatenate([peaks, additional_frames]))\n",
    "        else:\n",
    "            key_frame_indices = peaks[:num_segments]\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(16, 9))  # 16:9 aspect ratio\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[1, 2])\n",
    "        \n",
    "        # Plot temporal saliency\n",
    "        ax1 = plt.subplot(gs[0])\n",
    "        ax1.plot(frame_indices, temporal_attention_smoothed, color='blue', alpha=0.7, linewidth=2)\n",
    "        ax1.scatter(frame_indices[key_frame_indices], temporal_attention_smoothed[key_frame_indices], color='red', s=100, zorder=5)\n",
    "        for idx in key_frame_indices:\n",
    "            ax1.axvline(x=frame_indices[idx], color='gray', linestyle='--', alpha=0.5)\n",
    "        ax1.set_xlabel(\"Frame Number\", fontsize=18)\n",
    "        ax1.set_ylabel(\"Temporal Saliency\", fontsize=18)\n",
    "        ax1.set_xlim(frame_indices[0], frame_indices[-1])\n",
    "        ax1.set_ylim(0, 1)\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "        ax1.set_title(f\"Temporal Saliency and Key Frames - {video_name}\", fontsize=20)\n",
    "        \n",
    "        # Display key frames\n",
    "        ax2 = plt.subplot(gs[1])\n",
    "        ax2.axis('off')\n",
    "        frames_loaded = 0\n",
    "        for i, idx in enumerate(key_frame_indices):\n",
    "            frame_number = frame_indices[idx]\n",
    "            frame_path = os.path.join(results_dir, 'frames', f\"{video_name}_frame_{frame_number}_spatial_attention.png\")\n",
    "            \n",
    "            if os.path.exists(frame_path):\n",
    "                frame = cv2.imread(frame_path)\n",
    "                if frame is not None:\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    ax_sub = ax2.inset_axes([i/num_segments, 0, 1/num_segments - 0.01, 1], transform=ax2.transAxes)\n",
    "                    ax_sub.imshow(frame)\n",
    "                    ax_sub.axis('off')\n",
    "                    ax_sub.set_title(f\"Frame {frame_number}\", fontsize=14)\n",
    "                    frames_loaded += 1\n",
    "                else:\n",
    "                    print(f\"Failed to load frame: {frame_path}\")\n",
    "            else:\n",
    "                print(f\"Frame not found: {frame_path}\")\n",
    "        \n",
    "        if frames_loaded == 0:\n",
    "            print(f\"No frames were loaded for {video_name}. Check the 'frames' directory and file names.\")\n",
    "        else:\n",
    "            print(f\"Successfully loaded {frames_loaded} frames for {video_name}.\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        output_path = os.path.join(results_dir, f\"{video_name}_sample_frames.png\")\n",
    "        plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Sample frames visualization saved to: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error in create_sample_frames_visualization for video {video_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def load_video_labels(label_file):\n",
    "    video_labels = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                video_name, label = parts\n",
    "                video_labels[video_name.split('.')[0]] = int(label)  # Remove .mp4 extension\n",
    "            else:\n",
    "                logging.warning(f\"Skipping invalid line: {line.strip()}\")\n",
    "    logging.info(f\"Loaded {len(video_labels)} video labels\")\n",
    "    logging.info(f\"Unique labels in the dataset: {set(video_labels.values())}\")\n",
    "    return video_labels\n",
    "\n",
    "def get_videos_by_label(video_labels, target_label):\n",
    "    matching_videos = [video for video, label in video_labels.items() if label == target_label]\n",
    "    logging.info(f\"Found {len(matching_videos)} videos for label {target_label}\")\n",
    "    return matching_videos\n",
    "\n",
    "def process_videos(config):\n",
    "    extractor = AttentionExtractor(config['model_name'])\n",
    "    \n",
    "    video_labels = load_video_labels(config['label_file'])\n",
    "    \n",
    "    target_videos = get_videos_by_label(video_labels, config['target_label'])\n",
    "    \n",
    "    if not target_videos:\n",
    "        logging.warning(f\"No videos found for label {config['target_label']}\")\n",
    "        return\n",
    "\n",
    "    for video_name in tqdm(target_videos, desc=\"Processing videos\"):\n",
    "        video_path = os.path.join(config['video_directory'], video_name + '.mp4')\n",
    "        \n",
    "        if not os.path.exists(video_path):\n",
    "            logging.warning(f\"Video file not found: {video_path}\")\n",
    "            continue\n",
    "        \n",
    "        video_output_dir = os.path.join(config['output_directory'], video_name)\n",
    "        predicted_label, frames_dir, json_path, heatmap_video_path = process_video(video_path, video_output_dir, extractor)\n",
    "        \n",
    "        create_sample_frames_visualization(video_name, results_dir=video_output_dir)\n",
    "        \n",
    "        print(f\"Processed {video_name}\")\n",
    "        print(f\"Predicted Label: {predicted_label}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = {\n",
    "        'model_name': 'facebook/timesformer-base-finetuned-k400',\n",
    "        'video_directory': 'dataprocess/test_video',\n",
    "        'output_directory': 'video_results',\n",
    "        'label_file': 'dataprocess/kinetics400_val_list_videos.txt',\n",
    "        'target_label': int(input(\"Enter the target label number: \"))\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        process_videos(config)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice:\n",
    "'target_label': int(input(\"Enter the target label number: \")) \n",
    "This is only for manully test. \n",
    "When it is integrated to a service, There is no need to manually inset label. \n",
    "the label number should be automatically retrieved from the label txt file. \n",
    "The config file addresses are also for test. When it becomes a server. Inputs and outputs should be transfered through REST API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
